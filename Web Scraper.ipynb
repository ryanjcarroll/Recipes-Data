{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping from Allrecipes.com\n",
    "\n",
    "In order to compile a dataset of recipes for this project, we will first need to use web scraping and build a JSON object.  For this, we will send requests to www.allrecipes.com and parse their recipe cards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set how many pages to scrape recipes from\n",
    "first_page = 1\n",
    "last_page = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty json file to store recipe data\n",
    "data = []\n",
    "with open('recipes.json','w') as out_file:\n",
    "    json.dump(data, out_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(title, layout, picture, servings, ingredients, method, prep_time, cook_time, additional_time, total_time):\n",
    "    with open('recipes.json') as in_file:\n",
    "        data = json.load(in_file)\n",
    "    \n",
    "    # if this recipe title already exists in the data, do not add it again\n",
    "    already_exists = False\n",
    "    for recipe in data:\n",
    "        if recipe['title'] == title:\n",
    "            already_exists = True\n",
    "    \n",
    "    # if a new recipe, append to the json object and dump back to the file\n",
    "    if not already_exists:\n",
    "        print(\"Saved: {} \".format(title))\n",
    "        new_recipe = {}\n",
    "        new_recipe['title'] = title\n",
    "        new_recipe['layout'] = layout\n",
    "        new_recipe['picture'] = picture\n",
    "        new_recipe['ingredients'] = ingredients\n",
    "        new_recipe['method'] = method\n",
    "        new_recipe['servings'] = servings\n",
    "        new_recipe['prep_time'] = prep_time\n",
    "        new_recipe['cook_time'] = cook_time\n",
    "        new_recipe['additional_time'] = additional_time\n",
    "        new_recipe['total_time'] = total_time\n",
    "\n",
    "        data.append(new_recipe)\n",
    "    \n",
    "        with open('recipes.json', 'w') as out_file:\n",
    "            json.dump(data, out_file, indent=4)\n",
    "    else:\n",
    "        print(\"Already Exists: {} \".format(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Web Scraper\n",
    "\n",
    "Note that allrecipes has two different HTML layouts for their recipe pages, a regular layout and a layout which supports shopping for ingredients directly from the recipe page.  These two layouts have the information we need in different locations, so we need to differentiate them.  If the title element we initially search for is set to 'None', we have to instead look for the elements where they would be in the second (shopper) layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(first_page, last_page + 1):\n",
    "    # request the main allrecipes page which lists the top recipes\n",
    "    source = requests.get(\"https://www.allrecipes.com/recipes?page=\" + str(page))\n",
    "    print(\"PARSING PAGE {}\".format(page))\n",
    "    doc = bs(source.text,'html.parser')\n",
    "    \n",
    "    # find each recipe linked on the main page, and open their links one by one\n",
    "    recipe_cards = doc.select('a.fixed-recipe-card__title-link')\n",
    "\n",
    "    for card in recipe_cards:\n",
    "        # these are the values we will scrape for.  We first declare them as empty strings and lists\n",
    "        layout = 0\n",
    "        ingredients_list = []\n",
    "        method_list = []\n",
    "        title, picture = '', ''\n",
    "        prep_time, cook_time, total_time, additional_time, servings, = '','','','',''\n",
    "        \n",
    "        #open the page for each recipe card and parse its html\n",
    "        recipe_page_source = requests.get(card['href'])        \n",
    "        recipe_main = bs(recipe_page_source.text,'html.parser')\n",
    "        \n",
    "        # search for the values we declared above\n",
    "        title = recipe_main.select_one('.recipe-summary__h1')\n",
    "        if title is not None:\n",
    "            #for ordinary formatting layout (1)\n",
    "            layout = 1\n",
    "            title = title.text\n",
    "            picture = recipe_main.select_one('.rec-photo').attrs['src']\n",
    "            ingredients = recipe_main.select('.recipe-ingred_txt')\n",
    "            method = recipe_main.select('.recipe-directions__list--item')\n",
    "            servings = recipe_main.select_one('#metaRecipeServings')['content']\n",
    "            \n",
    "            meta_item_types = recipe_main.select('.prepTime__item--type')\n",
    "            meta_item_times = recipe_main.select('.prepTime__item--time')\n",
    "            \n",
    "            for label, time in zip(meta_item_types, meta_item_times):\n",
    "                if label.text == 'Prep':\n",
    "                    prep_time = time.text\n",
    "                elif label.text =='Cook':\n",
    "                    cook_time = time.text\n",
    "                elif label.text == 'Additional':\n",
    "                    additional_time = time.text\n",
    "                elif label.text == 'Ready In':\n",
    "                    total_time = time.text                \n",
    "                \n",
    "        # if the title is 'None', then the page must be in the shopper formatting layout\n",
    "        else:\n",
    "            # for shopper formatting layout (2)\n",
    "            layout = 2\n",
    "            title = recipe_main.select_one('h1.headline.heading-content').text\n",
    "            picture = recipe_main.select_one('.inner-container > img').attrs['src']\n",
    "            ingredients = recipe_main.select('span.ingredients-item-name')\n",
    "            method = recipe_main.select('div.paragraph > p')\n",
    "            meta_items = recipe_main.select('div.recipe-meta-item')\n",
    "\n",
    "            for item in meta_items:\n",
    "                parts = item.select('div')\n",
    "                header = parts[0].text.strip()\n",
    "                body = parts[1].text.strip()\n",
    "                    \n",
    "                if header == 'prep:':\n",
    "                    prep_time = body\n",
    "                elif header =='cook:':\n",
    "                    cook_time = body\n",
    "                elif header == 'additional:':\n",
    "                    additional_time = body\n",
    "                elif header == 'total:':\n",
    "                    total_time = body\n",
    "                elif header == 'Servings:':\n",
    "                    servings = body\n",
    "        \n",
    "        # compile a list of ingredients for the current recipe\n",
    "        for ingredient in ingredients:\n",
    "            if ingredient.text != 'Add all ingredients to list' and ingredient.text != '':\n",
    "                ingredients_list.append(ingredient.text.strip())\n",
    "            \n",
    "        # compile a list of method instructions for the current recipe\n",
    "        for instruction in method:\n",
    "            method_list.append(instruction.text.strip())\n",
    "        \n",
    "        # add this to the json string being built by our custom JsonBuilder class\n",
    "        save_to_json(title, \n",
    "                    layout, \n",
    "                    picture, \n",
    "                    servings, \n",
    "                    ingredients_list, \n",
    "                    method_list, \n",
    "                    prep_time, \n",
    "                    cook_time, \n",
    "                    additional_time, \n",
    "                    total_time\n",
    "                   )\n",
    "        \n",
    "print(\"FINISHED PARSING\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
